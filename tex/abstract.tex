\begin{abstract}


  Streaming sensor processing forms a foundational workload for
  embedded, mobile, and internet-of-things. Stream processing on these
  platforms requires both reliable performance and low energy, and two
  challenges must be addressed to meet these conflicting requirements.
  The first is \emph{complexity}: hardware exposes heterogeneous
  resources which interact in complicated ways. The second is
  \emph{dynamics}: performance must keep up with the data stream
  despite unpredictable changes in operating environment.  Prior work
  shows that machine learning addresses the complexity challenge and
  control systems tackle dynamics, but streaming sensor processing on
  energy-limited devices requires that both challenges be met
  simultaneously.

  To address both complexity and dynamics, we propose \SYSTEM{}, a
  resource management system that integrates hierarchical Bayesian
  learning with a lightweight control system.  The learning framework
  runs on a remote server aggregating data from multiple applications
  and devices to estimate performance/energy models for different
  resource configurations.  The controller runs on energy-limited
  devices using the learned models to deliver required performance for
  streaming processing with minimal energy.  We test \SYSTEM{} by
  implementing its learning on an x86 server and stream processing on
  four heterogeneous ARM big.LITTLE devices. We test in both
  \emph{stable} and \emph{unstable} environments (where available
  resources change over time) and we compare to state-of-the-art
  learning and control approaches.  In all test scenarios, \SYSTEM{}
  provides the lowest error between the required and delivered
  performance. Depending on the scenario, \SYSTEM{} also provides
  12-25\% average energy reduction compared to state-of-the-art
  learning and control approaches.  Additionally, \SYSTEM{}'s worst
  case performance and energy is uniformly better than prior
  approaches.  Thus, \SYSTEM{}'s unique combination of learning and
  control is well-suited to supporting streaming sensor processing in
  embedded, mobile, and IoT platforms.



  \PUNT{ Mobile systems must deliver performance to interactive
    applications while simultaneously conserving resources to extend
    battery life.  There are two central challenges to meeting these
    conflicting goals: (1) the complicated optimization spaces arising
    from hardware heterogeneity and (2) dynamic changes in application
    behavior and resource availability.  Machine learning techniques
    handle complicated optimization spaces, but do not incorporate
    models of system dynamics; control theory provides formal
    guarantees of dynamic behavior, but struggles with non-linear
    system models.  In this paper, we propose \SYSTEM{}, a combination
    of learning and control techniques to meet performance
    requirements on heterogeneous devices in unpredictable
    environments.  \SYSTEM{} combines a hierarchical Bayesian model
    (HBM) with a lightweight control system (LCS).  The HBM runs
    remotely, learning customized performance/power models.  The LCS
    runs on the mobile system and tunes resource usage to meet
    performance goals.  The Performance Hash Table (PHT) is the
    interface between the two and allows the LCS to apply the learned
    models in constant time.  We test \SYSTEM{}'s ability to manage
    ARM big.LITTLE systems.  Compared to existing learning and control
    methods, \SYSTEM{} delivers more reliable performance -- only 2\%
    error compared to 4.5-5.4\% for learning and 4.7\% for control --
    and lower energy -- within 7\% of optimal on average as compared
    to 25-52\% for learning and 26\% for control. Furthermore, we
    demonstrate \SYSTEM{}'s ability to meet performance and energy
    goals in dynamic systems with phase changes and multiple
    applications running on the same system.  }



  \PUNT{ When multiple applications compete for resources, these
    numbers improve: 7\% error compared to 11-15\% for learning and
    9\% for control and improvements of 2-20\% and 3\%, respectively,
    in energy efficiency.}
\end{abstract}
