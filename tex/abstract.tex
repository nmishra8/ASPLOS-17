\begin{abstract}
  Intelligent resource management is essential for modern computing
  systems that must provide reliable performance with minimal energy.
  Two central challenges arise when allocating system resources to
  meet these conflicting goals: (1) \emph{complexity}---modern
  hardware exposes diverse resources with complicated
  interactions---and (2) \emph{dynamics}---performance must be
  reliable despite unpredictable changes in operating environment or
  input.  Machine learning handles complicated optimization spaces,
  but does not model system dynamics; control theoretic models work well in relatively simple yet dynamic system behavior, but struggles with complex,
  non-convex resource interaction. We therefore propose \SYSTEM{}, a
  parameter-free combination of learning and control techniques that automatically
  adjusts resource usage to meet performance requirements in complex,
  dynamic environments.  \SYSTEM{}'s key contribution is the self-tuning interface
  that allows control to use learned models with low overhead while
  preserving control theoretic formal guarantees.  \SYSTEM{}'s principled combination of learning and control makes it
  the first approach to provide formal guarantees of convergence to
  the required performance without prior knowledge of application
  behavior. We implement \SYSTEM{} and test its ability to meet
  application performance requirements heterogeneous ARM big.LITTLE
  architectures both individually and when other applications
  dynamically enter the system to compete for resources.  We compare
  \SYSTEM{} to several state-of-the-art learning and control solutions
  and to a naive combination of existing methods that does not use the
  \SYSTEM{} interface. We find that \SYSTEM{} provides the most
  reliable performance and the best energy efficiency, while the naive
  combination of learning and control is uniformly worse than prior
  approaches in both metrics. 
  



  \PUNT{ Mobile systems must deliver performance to interactive
    applications while simultaneously conserving resources to extend
    battery life.  There are two central challenges to meeting these
    conflicting goals: (1) the complicated optimization spaces arising
    from hardware heterogeneity and (2) dynamic changes in application
    behavior and resource availability.  Machine learning techniques
    handle complicated optimization spaces, but do not incorporate
    models of system dynamics; control theory provides formal
    guarantees of dynamic behavior, but struggles with non-linear
    system models.  In this paper, we propose \SYSTEM{}, a combination
    of learning and control techniques to meet performance
    requirements on heterogeneous devices in unpredictable
    environments.  \SYSTEM{} combines a hierarchical Bayesian model
    (HBM) with a lightweight control system (LCS).  The HBM runs
    remotely, learning customized performance/power models.  The LCS
    runs on the mobile system and tunes resource usage to meet
    performance goals.  The Performance Hash Table (PHT) is the
    interface between the two and allows the LCS to apply the learned
    models in constant time.  We test \SYSTEM{}'s ability to manage
    ARM big.LITTLE systems.  Compared to existing learning and control
    methods, \SYSTEM{} delivers more reliable performance -- only 2\%
    error compared to 4.5-5.4\% for learning and 4.7\% for control --
    and lower energy -- within 7\% of optimal on average as compared
    to 25-52\% for learning and 26\% for control. Furthermore, we
    demonstrate \SYSTEM{}'s ability to meet performance and energy
    goals in dynamic systems with phase changes and multiple
    applications running on the same system.  }



  \PUNT{ When multiple applications compete for resources, these
    numbers improve: 7\% error compared to 11-15\% for learning and
    9\% for control and improvements of 2-20\% and 3\%, respectively,
    in energy efficiency.}
\end{abstract}
