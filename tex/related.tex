\section{Related Work}

We discuss related work in managing resources to meet performance
goals and reduce energy.  

\subsection{Machine Learning}
There are a huge array of different learning techniques that are
applicable to different problems.  As discussed in in \secref{framework:HBM}
we break learning for resource management into three categories:
offline, online, and hybrid approaches.  

\subsubsection{Offline Learning}
The offline approaches build models before deployment and then use
those fixed models to allocate resources
\cite{Yi2003,LeeBrooks2006,CPR,ChenJohn2011,petabricksStatic}.  In
these approaches, the model-building phase is generally very expensive,
requiring both a large number of samples and substantial computation
to turn those samples into a model that accurately captures the
relationship between the observed features and the behavior to be
estimated.  Applying the model online, however, tends to be low
overhead.  The main drawback is that the models are not updated as the
system runs, so there is no chance to correct mistakes or adapt to
specific workloads.

A good example of an offline approach applies learning to render web
pages on mobile systems with low energy \cite{reddiHPCA2013}.  This
system is similar in spirit to \SYSTEM{}.  It builds an offline model
mapping web page features into estimations of performance for
different core types.  When a new page is downloaded, the system
quickly estimates the resource need to render the web page and uses the
lowest energy resources that will still maintain user satisfaction.
The mapping of web pages to resource use is very complicated and this
approach deals with that complication.  It does not, however, address
system dynamics; \eg{} when other apps are running concurrently with the
web browser.

\subsubsection{Online Learning}
Online techniques use observations of the current application to tune
system resource usage for that application
\cite{Li2006,Flicker,ParallelismDial,Ponamarev,petabricksDynamic,LeeBrooks}.
For example, Flicker is a configurable architecture and optimization
framework that uses only online models to maximize performance under a
power limitation \cite{Flicker}.  Another example, ParallelismDial,
uses online adaptation to tailor parallelism to application workload
\cite{ParallelismDial}.



\subsubsection{Hybrid Approaches}
Some approaches combine offline predictive models with online
adaptation
\cite{Zhang2012,packandcap,Winter2010,dubach2010,Koala,Cinder,
  wu2012inferred}.  For example, Dubach et al.  propose such a combo
for optimizing the microarchitecture of a single core
\cite{dubach2010}.  Such predictive models have also been employed at
the operating systems level to manage system energy consumption \cite{Koala,Cinder}.
\cite{wu2012inferred}.


Still other approaches combine offline modeling with online model
updates \cite{JouleGuard,Bitirgen2008,Ipek}.  Bitirgen et
al use an artificial neural network to allocate resources to multiple
applications in a multicore \cite{Bitirgen2008}.  The neural network
is trained offline and then adapted online using measured feedback.
This approach optimizes performance but does not consider power or
energy minimization.  LEO, the system we extend in this paper, also
uses a combination of offline and online approaches.  LEO collects
data about a number of applications offline and combines that with a
small number of observations made online for the current application
\cite{LEO}.

\subsection{Control}
Almost all control solutions can be thought of as a combination of
offline model building with online adaptation.  Usually the model
building involves substantial empirical measurement and statistical
regression to build a model that is then used to synthesize a control
system
\cite{Wu2004,TCST,Chen2011,PTRADE,POET,ControlWare,Agilos,Rajkumar,Sojka,Raghavendra2008}.
The combination of offline
learning and control works well over a narrow range of applications, as the offline models capture the
general behavior of the entire class of application and require
negligible online overhead.  This focused approach is extremely
effective for multimedia applications
\cite{grace2,flinn99,flinn2004,xtune,TCST} and web-servers
\cite{Horvarth,LuEtAl-2006a,SunDaiPan-2008a} because the workloads can
be characterized ahead of time so that the models produce sound
control.

Indeed, the need for good models is the central tension in developing
control for computing systems.  It is always possible to build a
controller for a specific application and system by extensively
modeling that pair.  More general controllers which work with a range
of applications have addressed this issue with models in several ways.
Some provide control libraries that encapsulate control
functionality and require users to input a model
\cite{ControlWare,Sojka,Rajkumar,POET}.  Others
automatically synthesize both a model and a controller for either
hardware \cite{josep-isca2016} or software \cite{ICSE2014,FSE2015}.
JouleGuard combines learning for energy efficiency with control for
managing application parameters \cite{JouleGuard}.  In JouleGuard, a
learner adapts the controller's coefficients to model certainty, but
JouleGuard's learner does not produce a new model for the controller.
Because JouleGuard's learner runs on the same device as the controlled
application, it must be computationally efficient and thus it cannot
identify correlations across applications or even different resource
configurations.  \SYSTEM{} is unique in that a remote server generates
an application-specific model automatically.  By offloading the
learning task, we are able to (1) combine data from many applications
and systems and (2) apply computationally expensive, but highly accurate
learning techniques.

Perhaps the most similar approach to \SYSTEM{} is Carat \cite{carat}.
Carat aggregates data across many mobile devices and sends a report to
human users about how to configure their device to increase battery
life.  While both Carat and \SYSTEM{} learn across devices, they have
very different goals.  Carat's goal is to return very high-level
information to human users; \eg{} you should update a driver to extend
battery life.  \SYSTEM{} returns lower-level models to another
automated system that will apply those models to save energy.

