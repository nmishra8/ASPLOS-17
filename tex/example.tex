\section{Background and Motivation}
\label{sec:example}
Many machine learning approaches estimate the most energy efficient
resource allocation for an application.  These include \emph{offline}
techniques that build models using a training set and then apply those
models to new applications
\cite{Yi2003,LeeBrooks2006,CPR,ChenJohn2011,reddiHPCA2013,Paragon,PUPiL,quasar}.
Other approaches use \emph{online} techniques that construct models
dynamically as an application runs
\cite{Li2006,Flicker,ParallelismDial,Ponamarev,LeeBrooks}.  Finally,
\emph{hybrid} techniques combine offline modeling with online model
updates \cite{Zhang2012,packandcap,Winter2010,dubach2010,Koala,Cinder,
  wu2012inferred,LEO}.

Control theory provides techniques for maintaining desired behavior in
dynamic systems \cite{Hellerstein2004a}. \emph{Adaptive controllers}
or \emph{self-tuning regulators} adjust their internal models in
response to dynamic changes; they are especially useful in webservers
with fluctuating request rates
\cite{Horvarth,LuEtAl-2006a,SunDaiPan-2008a} and multimedia
applications with dynamically varying inputs
\cite{TCST,Agilos,grace2}.  Prior adaptive control solutions, however,
incorporate application-specific models into the control
implementation---making a controller for a web server unsuitable for
video playback.  Prior work has generalized adaptive control design by
exposing key parameters to users who customize control to their needs
\cite{ControlWare,POET}.  User customization provides greater
flexibility, but the controller will not converge to the desired
performance if the custom control models do not accurately capture the
relationship between resources and performance.  This practice means
users must not only be experts in their application domain, but must
also have sufficient control knowledge to specify robust models.

\subsection{\emph{Learning} Complexity}
\begin{figure}
\centering
  \subfloat[]
  {
    \includegraphics[width=.25\textwidth]{figures/STREAM-contour.png}
    \label{fig:STREAM_contour}
  }
  \subfloat[]
  {
    \input{img/STREAM-example-resized.tex}
    \label{fig:STREAM_timeline}
  }
  \caption{(a) \texttt{STREAM} performance as a function of
    configuration.  (b) Managing \texttt{STREAM}'s performance:
    \emph{Learning} handles the complex configuration space, but
    \emph{control} oscillates.}
  \label{fig:learning-models1}
\end{figure}

We demonstrate how well learning handles complex resource interaction
for \texttt{STREAM} on an ARM big.LITTLE processor with four big,
high-performance cores and four LITTLE, energy efficient cores.  The
big cores support 19 clock speeds, while the LITTLE cores support 14.


\figref{fig:STREAM_contour} shows the relationship between resources
and performance for \texttt{STREAM}.  This memory-bound application
has complicated behavior: due to memory pressure, the LITTLE cores'
memory hierarchy cannot deliver the required performance.  The big
cores' more powerful memory system delivers much greater performance,
but the peak occurs with 3 big cores.  Furthermore, at low
clockspeeds, these 3 big cores cannot saturate the memory bandwidth,
while at high clockspeeds the performance drops as the processor
overheats and triggers thermal management.  For \texttt{STREAM}, the
peak speed occurs with 3 big cores at 1.2 GHz, and it is not efficient
to spend any time on the LITTLE cores.  \texttt{STREAM}, however, does
not have distinct phases, so once a resource allocator finds the most
energy efficient configuration, it simply needs to maintain it.
\TODO{We should change the levels in the contour so there is a clear
  maximum at 3 cores and a middle clock speed.}

\figref{fig:STREAM_timeline} shows 20 iterations of allocating
resources to \texttt{STREAM} using both learning \cite{LEO} and
adaptive control \cite{POET}.  The x-axis shows iteration number and
the y-axis shows performance normalized to the requirement.  The
\emph{learning} approach estimates the application's performance and
power for all configurations and uses the lowest power configuration
that delivers the required performance.  The \emph{adaptive
  controller} begins with a generic model of power/performance
tradeoffs.  As the controller runs, it measures performance and
adjusts both the allocated resources and its own parameters in
response to online measurements.  While many controllers use linear
models, this adaptive controller dynamically adjusts to
non-linearities with a series of linear approximations; however, the
controller is sensitive to model inaccuracies, which cause the
oscillations that lead to performance violations.  This behavior
occurs because the controller's adaptive mechanisms cannot handle the
STREAM's complexity, a known limitation of adaptive control systems
\cite{ControlWare,POET,ICSE2014}.  Hence, the \emph{learner}'s ability
to model complex behavior is crucial in this example.

\subsection{\emph{Controlling} Dynamics}

\begin{figure}
\centering
  \subfloat[]
  {
    \includegraphics[width=.25\textwidth]{figures/BODYTRACK-contour.png}
    \label{fig:BODYTRACK_contour}
  }
  \subfloat[]
  {
    \input{img/BODYTRACK-example-resized.tex}
    \label{fig:BODYTRACK_timeline}    
  }
  \caption{(a) \texttt{bodytrack} performance as a function of
    configuration. (b) Managing \texttt{bodytrack}'s performance with
    another application: \emph{control} detects the change (at the
    vertical dashed line) and immediately adjusts, but \emph{learning}
    has no mechanism to handle these dynamics. }
  \label{fig:control}
\end{figure}


We now consider a dynamic environment.  We begin with
\texttt{bodytrack} running alone on the system.  Halfway through its
execution, we launch a second application---\texttt{STREAM}---on a
single big core, dynamically altering resource availability.
\figref{fig:BODYTRACK_contour} shows \texttt{bodytrack}'s behavior.
It achieves the best performance on 4 big cores at the maximum
clockspeed; the 4 LITTLE cores offer more energy-efficient execution
at the cost of performance.  For \texttt{bodytrack}, the challenge is
determining how to split time between the LITTLE and big cores to
conserve energy while still meeting the performance requirements.

\figref{fig:BODYTRACK_timeline} shows the results of this experiment.
The vertical dashed line---at frame 99---represents when the second
application begins.  The figure clearly shows adaptive control's
benefits in this dynamic scenario.  When the second application
starts, the controller detects \texttt{bodytrack}'s performance
dip--rather than detecting the new application specifically---and it
changes resource allocation (increasing clockspeed and moving
bodytrack from 4 to 3 big cores).  The learning system however, does
not have any inherent mechanism to measure the change or adapt to the
altered performance.  While we could theoretically add feedback to the
learner and re-estimate the configuration space whenever the
environment changes, doing so is impractical due to high overhead for
learners capable of handling this complexity
\cite{Paragon,quasar,LEO}.


\subsection{Challenges of Parameter-free Control}
The adaptive controller requires user-specified parameters and
\figref{fig:STREAM_timeline} shows what happens if users get those
parameters wrong. Perhaps the most essential parameter for a
controller is the \emph{pole} of its characteristic equation.  Control
engineers tune the pole with a model---trading response time for noise
sensitivity.  This model may be an abstraction, but it is considered
\emph{ground truth} \cite{Hellerstein2004a}, meaning that all possible
configurations the controller might select have been directly measured
for some input.  \SYSTEM{}, however, tunes the pole based on an
estimated model, which may have noise and/or errors.



%\begin{wrapfigure}{r}{0.5\columnwidth} 
\begin{figure}
\centering
\input{img/BODYTRACK-example2-resized.tex}
\caption{Comparison of carefully tuned and default poles.}
\label{fig:not-simple}
\end{figure}
%\end{wrapfigure}
To demonstrate the pole's importance when using a learned model, we
again control \texttt{bodytrack}, this time using the adaptive
controller from the previous subsection with a model produced by the
learner from the first subsection.  We compare the results with a
carefully tuned pole to those using the default pole provided by the
controller developers \cite{POET}.

\figref{fig:not-simple} shows the results.  The carefully tuned pole
converges because the pole accounts for the learned model's error. The
default pole, however, oscillates around the performance target,
resulting in a number of missed deadlines.  Additionally, the frames
that exceed the desired performance waste energy because they spend
more time on the big, inefficient cores. The pole parameterizes the
system's \emph{inertia}---dictating how fast it should react to
environmental changes.  If the estimated model is noisy, the
controller should trust it less and move slowly. Rather than require
users with both computing and control knowledge to tune the pole,
\emph{\SYSTEM{} incorporates the learner's confidence interval and
  estimated variance to compute a pole that provides probabilistic
  convergence guarantees.}


