\section{Motivational Example}
\label{sec:example}

Learning and control systems have complementary strengths and
weaknesses.  In this section we present two simple examples that
illustrate these properties.  We run our examples on mobile
development boards featuring Samsung's Exynos 5 Octa with an ARM
big.LITTLE architecture.  We first consider the problem of estimating
the performance for an application running on this architecture.  We
then consider meeting application performacne goals in a dynamic
environment.  


\TODO{We also need to add references here.}
\subsection{Complexity}
\figref{contour} illustrates how performance for applications vary as
a function of resources on our system.  These plots show cores on the
x-axis and clock frequency on the y-axis.  Performance is shown as
hue, with darker colors representing higher performance.

\TODO{Let's put the discussion of the contour plots in here. We should
  make the points that 1) some of these are easy to estimate (smooth)
  some are harder, 2) if we want to be general we have to handle the
  hard ones, and 3) the vast majority of control systems rely on
  linear models which are not appropriate here.}

\begin{figure}[t]
  \input{img/lavamd-example.tex}
   \vskip -1em
  \caption{Performance Control for LAVAMD}
  \label{fig:lavamd-example}
\end{figure}

\subsection{Dynamics}

\begin{figure}[t]
  \input{img/kmeans-example.tex}
   \vskip -1em
  \caption{Performance Control for KMEANS}
  \label{fig:kmeans-example}
\end{figure}



To illustrate a dynamic system we launch \TODO{app} with a performance
goal.  We use an existing control system to ensure that these goals
are met.  Halfway through execution, we launch a second application on
one of the big cores.  This new application alters the performance of
\TODO{app} and the control adjusts by allocating more resources.  We
compare the control system to a learning approach.

\figref{dynamic} shows the results of this simple experiment, with
time on the x-axis and performance on the y-axis, normalized to the
target.  The vertical dashed line shows when the second application
begins.  The figure clearly shows the benefits of a control system in
this scenario.  After a small dip in performance, the controller
adjusts to return it back to the desired level.  The learning system
however, does not have any inherent mechanism to adapt to these
changes.  While we could theoretically relearn the tradeoff space
everytime the environment changes, this is obviously impractical.
Furthermore, control systems already have mechanisms for managing
dynamics.  The primary contribution of this paper is to combine a
learning technique that can handle complexity -- as shown in \figref{}
-- with a control system that can handle dynamics -- as shown in
\figref{}. 

